<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Principles &#8212; HiPERCAM pipeline 1.6.7.dev17+gf476407b5 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap-astropy.css?v=177ce38d" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css?v=fd3f3429" />
    
    <script src="_static/documentation_options.js?v=c92ee6e6"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>
    <script type="text/javascript" src="_static/copybutton.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="File organisation" href="organisation.html" />
    <link rel="prev" title="Reduction" href="reduction.html" />
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,600' rel='stylesheet' type='text/css'/>

  </head><body>
<div class="topbar">
  <a class="brand" title="Documentation Home" href="index.html"><span id="logotext1">astro</span><span id="logotext2"></span><span id="logotext3">:docs</span></a>
  <ul>
    
    <li><a class="homelink" title="Astropy Homepage" href="http://www.astropy.org"></a></li>
    <li><a title="General Index" href="genindex.html">Index</a></li>
    <li><a title="Module Index" href="py-modindex.html">Modules</a></li>
    <li>
      
      
<form action="search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
      
    </li>
  </ul>
</div>

<div class="related">
    <h3>Navigation</h3>
    <ul>
      <li class="right">
	<a href="organisation.html" title="File organisation">
	  next &raquo;
	</a>
      </li>
      <li class="right">
	<a href="reduction.html" title="Reduction">
	  &laquo; previous
	</a>
	 |
      </li>
      <li>
	<a href="index.html">HiPERCAM pipeline 1.6.7.dev17+gf476407b5 documentation</a>
	 &#187;
      </li>
      <li><a href="observers.html" accesskey="U">Observer’s guide</a> &#187;</li>
      
      <li>Principles</li> 
    </ul>
</div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="principles">
<h1>Principles<a class="headerlink" href="#principles" title="Link to this heading">¶</a></h1>
<p>This document lays out the technical background behind the operating
principles of the HiPERCAM software.  HiPERCAM’s <a class="reference internal" href="commands.html#hipercam.scripts.reduce" title="hipercam.scripts.reduce"><code class="xref py py-func docutils literal notranslate"><span class="pre">reduce</span></code></a> implements two forms
of flux extraction, labelled either ‘normal’ or ‘optimal’. Normal extraction
is essentially a matter of adding up the flux above background in the target
aperture. Optimal extraction refers to a weighted extraction designed to yield
the best signal-to-noise for background-limited targets <a class="reference external" href="http://adsabs.harvard.edu/abs/1998MNRAS.296..339N">(Naylor 1998)</a>. This page discusses
some details of the implementations and the advantages and disadvantages of
the various options, and summarises some other aspects of how things work.</p>
<nav class="contents local" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#aperture-positioning" id="id4">Aperture positioning</a></p></li>
<li><p><a class="reference internal" href="#target-detection" id="id5">Target detection</a></p></li>
<li><p><a class="reference internal" href="#sky-background-estimation" id="id6">Sky background estimation</a></p></li>
<li><p><a class="reference internal" href="#normal-extraction" id="id7">Normal extraction</a></p></li>
<li><p><a class="reference internal" href="#profile-fitting" id="id8">Profile fitting</a></p></li>
<li><p><a class="reference internal" href="#optimal-photometry" id="id9">Optimal photometry</a></p></li>
</ul>
</nav>
<section id="aperture-positioning">
<span id="id1"></span><h2><a class="toc-backref" href="#id4" role="doc-backlink">Aperture positioning</a><a class="headerlink" href="#aperture-positioning" title="Link to this heading">¶</a></h2>
<p>A key problem faced by the pipeline is how to locate the targets from frame to
frame given that the telescope moves, and conditions vary. The usual option
in the <a class="reference internal" href="commands.html#hipercam.scripts.reduce" title="hipercam.scripts.reduce"><code class="xref py py-func docutils literal notranslate"><span class="pre">reduce</span></code></a> configuration file is the <code class="docutils literal notranslate"><span class="pre">[apertures]</span></code> section is
<code class="docutils literal notranslate"><span class="pre">location</span> <span class="pre">=</span> <span class="pre">variable</span></code>. It’s worth understanding how this operates. In the
usual case one defines one or more targets as <code class="docutils literal notranslate"><span class="pre">reference</span></code> apertures in
<a class="reference internal" href="commands.html#hipercam.scripts.setaper" title="hipercam.scripts.setaper"><code class="xref py py-func docutils literal notranslate"><span class="pre">setaper</span></code></a>. The aperture movement inside <a class="reference internal" href="commands.html#hipercam.scripts.reduce" title="hipercam.scripts.reduce"><code class="xref py py-func docutils literal notranslate"><span class="pre">reduce</span></code></a> then proceeds through a two
step process as follows:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>First search for the first reference target in a box of half width
<code class="docutils literal notranslate"><span class="pre">search_half_width</span></code> around its last valid position. This
search is carried out by smoothing the image (<code class="docutils literal notranslate"><span class="pre">search_smooth_fwhm</span></code>)
and taking the location of
whatever local maximum exceeds a pre-defined threshold
(<code class="docutils literal notranslate"><span class="pre">fit_height_min_ref</span></code>) and lies closest to the last-measured position.
The position of this maximum is used as the starting position for a 2D
profile fit. This method is fairly robust against even bright cosmic rays
as long as they lie further from the expected position than the target.
The smoothing helps this as cosmic rays tend to be confined to 1 or 2 pixels.
If reference targets are chosen to be bright and isolated, one can carry
out broad searches which allow for very poor guiding. The shift measured
from the first reference star is used to provide a better starting position
for any remaining reference stars to improve things still more. This means
that you should try to make the first reference star that appears in an aperture
file for any given CCD the most robust of all. This is particularly the case if
you have to make <code class="docutils literal notranslate"><span class="pre">search_half_width</span></code> large because of bad guiding. Note that
“robust” means unlikely to jumpt to another star so the key aspect is that it has
no near stars of reference star type brightness. Following the
search, 2D profile fits are carried out and the mean x,y shift relative to
the starting position is calculated. If this stage fails (e.g.  because of
clouds), then the rest of the frame is skipped on the basis that if the
reference targets cannot be located, then no others will be
either. <strong>All</strong> the reference stars must be successfully relocated each
time. This means an increased chance of failure compared to a single
reference, but potentially can pay off in being more sensitive to
problems: the  parameter <code class="docutils literal notranslate"><span class="pre">fit_diff</span></code> is used for this by guarding against
mutually discrepant reference positions. Again this acts in a
severe all-or-nothing manner. The benefit is a lowered risk of losing the
reference position altogether. If you find are losing the location of the stars on some
frames then it is probably a case of adjusting the values of <code class="docutils literal notranslate"><span class="pre">search_half_width</span></code>,
<code class="docutils literal notranslate"><span class="pre">search_smooth_fwhm</span></code>, <code class="docutils literal notranslate"><span class="pre">fit_height_min_ref</span></code> and <code class="docutils literal notranslate"><span class="pre">fit_diff</span></code>.
``</p></li>
<li><p>Next, the positions of non-reference, non-linked apertures are
determined. This is done through 2D profile fits starting from the shift
determined from the reference targets. This allows a possibly wide-ranging
initial search step as used for the reference stars to be skipped. The
parameter <code class="docutils literal notranslate"><span class="pre">fit_max_shift</span></code> can be used to control how far the profile fits are
allowed to wander from the initial positions obtained via the reference
stars. If the fits to non-reference stars fail, and there are reference
stars available, an extraction will still be carried out. This allows one
to cross over deep eclipses while still extracting flux at the known
position offset of your target from the references.</p></li>
</ol>
</div></blockquote>
<p>The combination of the options available in <a class="reference internal" href="commands.html#hipercam.scripts.setaper" title="hipercam.scripts.setaper"><code class="xref py py-func docutils literal notranslate"><span class="pre">setaper</span></code></a> and the <a class="reference internal" href="commands.html#hipercam.scripts.reduce" title="hipercam.scripts.reduce"><code class="xref py py-func docutils literal notranslate"><span class="pre">reduce</span></code></a>
configuration file are a powerful means to track objects over many thousands of
exposures in a row. The main risk of failure comes when a combination of
clouds and cosmic rays cause a target to be too faint to register while a
cosmic ray does. Multiple reference stars and careful use of <code class="docutils literal notranslate"><span class="pre">fit_max_shift</span></code>
and <code class="docutils literal notranslate"><span class="pre">fit_diff</span></code> can help in such cases. A final option is <code class="docutils literal notranslate"><span class="pre">fit_alpha</span></code> which
enables averaging of the offset used to get from the reference stars to the
target position. This allows one to cope with, for example, stars that disappear
during eclipses, without simply fixing the offset in perpetuity using the link
option. <code class="docutils literal notranslate"><span class="pre">fit_alpha</span> <span class="pre">=</span> <span class="pre">0.01</span></code> for instance only applies a fraction of 0.01 of the
correction to the x,y offsets  measured on a given frame. This has the effect of
smoothing the offsets over the scale of 100 frames or so. This should make the relative
aperture positions less jumpy than simply applying them directly. Experimentation is
advised to compare and optimise results. Once the aperture positions are
determined, <a class="reference internal" href="commands.html#hipercam.scripts.reduce" title="hipercam.scripts.reduce"><code class="xref py py-func docutils literal notranslate"><span class="pre">reduce</span></code></a> moves onto extracting the flux.</p>
</section>
<section id="target-detection">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Target detection</a><a class="headerlink" href="#target-detection" title="Link to this heading">¶</a></h2>
<p>The first stage of target detection is a search over a smoothed image. The
peak height thresholds <code class="docutils literal notranslate"><span class="pre">fit_height_min_ref</span></code> and <code class="docutils literal notranslate"><span class="pre">fit_height_min_nrf</span></code> are
important at this point. The effect of smoothing on a single pixel can be written as</p>
<div class="math">
<p><span class="math">\hat{y} = \frac{\sum_i w_i y_i}{\sum_i w_i},</span></p>
</div><p>where the <span class="math">w_i</span> are the gaussian weights</p>
<div class="math">
<p><span class="math">w_i \propto \exp \left(-r^2/2\sigma^2\right),</span></p>
</div><p>with <span class="math">r</span> the distance in binned pixels from the particular pixel under
consideration, and <span class="math">\sigma</span> is the RMS of the smoothing being applied
(<span class="math">= \mathrm{FWHM}/2.3548</span>) and <span class="math">y_i</span> are the values
of the contributing surrounding pixels. A quantity of interest is the
statistical uncertainty of this smoothed value, since it is this which sets the
desirable threshold level. Assuming the contributing pixels are independent,
the variance is given by</p>
<div class="math">
<p><span class="math">V(\hat{y}) = \frac{\sum_i w^2_i V_i}{\left(\sum_i w_i\right)^2}.</span></p>
</div><p>Assuming <span class="math">\sigma \gg 1</span>, and that we are in a background-limited case
(which gives the minimum variance), the sums can be approximated as integrals
and one finds that</p>
<div class="math">
<p><span class="math">V(\hat{y}) \approx \frac{R^2 + B/G}{4\pi \sigma^2},</span></p>
</div><p>where <span class="math">R</span> is the RMS readout noise in ADU, <span class="math">B</span> is the
background level in ADU and <span class="math">G</span> is the gain in electrons per ADU.
This relation fails when <span class="math">4\pi \sigma^2 &lt; 1</span>, so the denominator should
not go below this value (such a small smoothing would be an odd choice in any
case). An obvious threshold would be thus be some multiple of the equivalent
standard deviation</p>
<div class="math">
<p><span class="math">S = \sqrt{V(\hat{y})} = \frac{\sqrt{R^2+B/G}}{\sqrt{4\pi} \sigma}</span></p>
</div><p>For example, assuming <span class="math">R = 4.5</span>, <span class="math">B = 20</span>, <span class="math">G = 1.2</span> and a smoothing FWHM of
10 leads to <span class="math">S = 0.40</span>. One would then expect to choose at least 3 times
this, and probably more because any given search area will include effectively
a number of “independent trials”, not just one, so the threshold will need
raising as a result. Choosing a lower threshold runs the risk of peaking up on
spurious noise peaks, especially when clouds are passing. This is not
desirable, particularly for reference targets. A target of seeing-limited peak
height <span class="math">h</span> in RMS seeing <span class="math">\sigma_S</span> binned pixels will end up with
height</p>
<div class="math">
<p><span class="math">\hat{h} = \frac{\sigma_S^2}{\sigma_S^2 + \sigma^2} h</span></p>
</div><p>in the smoothed image, and thus the signal-to-noise of the smoothed peak will
be</p>
<div class="math">
<p><span class="math">\frac{\hat{h}}{S} = \frac{\sigma_S^2}{\sigma_S^2 + \sigma^2}
\frac{\sqrt{4\pi} \sigma}{\sqrt{R^2+B/G}} h</span></p>
</div><p>when we are background-limited (the case of most interest). This is maximised
by choosing <span class="math">\sigma = \sigma_S</span>, so the smoothing FWHM ideally should match
the FWHM of the seeing (in terms of unbinned pixels). The smoothing is acting
as what is sometimes called a “matched filter”.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>At the moment, the search routine uses fixed height thresholds; I expect to
change them to depend upon the background level, so they will in future be
specified as a multiplier of the above estimate.</p>
</div>
</section>
<section id="sky-background-estimation">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">Sky background estimation</a><a class="headerlink" href="#sky-background-estimation" title="Link to this heading">¶</a></h2>
<p>The sky background is estimated from a circular annulus centred on each
target. The user can define the inner and outer radii. Inside <a class="reference internal" href="commands.html#hipercam.scripts.setaper" title="hipercam.scripts.setaper"><code class="xref py py-func docutils literal notranslate"><span class="pre">setaper</span></code></a> it is
possible to mask out obvious stars from the sky annulus for any target. To
some extent, the two methods implemented (median and clipped mean) should
eliminate contaminating stars, but they are not perfect and if you can see an
obvious star, it is best to mask it. You should, if possible, try to set the
sky annulus radii such that there is a much larger area of sky than in the
target aperture, i.e. <span class="math">R^2_\text{out}-R^2_\text{in} \gg
R^2_\text{targ}</span>, in order to minimise the uncertainty due to the sky
estimate. The downside of this is the possibility of picking up more nearby
stars, starting to overlap the sky annulus with the edge of the window
within which the target falls, and increasing the size so much that
quadratic variations in the sky background become important. Overlap of the
sky aperture with the edge of the window is not desirable as one always wants
the sky to be symmetrical around the object to eliminate any gradients in the
sky.</p>
</section>
<section id="normal-extraction">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">Normal extraction</a><a class="headerlink" href="#normal-extraction" title="Link to this heading">¶</a></h2>
<p>As indicated above, normal extraction is essentially a case of adding all the
pixels inside the inner circular aperture defining the target. It is not quite
as simple as this because the pixels are square-shaped (or rectangular for
non-equal binning factors) and not compatible with a circle, thus something
needs to be done about the pixels at the edge. If they are simply included or
excluded on the basis of how far their centres are from the centre of the
target aperture, one can suffer from pixellation noise that occurs when pixels
instantaneously appear or disappear owing to tiny change of target
position. To reduce this I use the commonly-adopted soft-edge weighting scheme
whereby a pixel which has its centre exactly on the edge of the circle gets
a weight of 0.5, which is linearly ramped from 0 to 1 as the pixel approaches
the aperture over a length scale comparable to its size.</p>
<p>An important element of normal extraction is the radius to extract the
target flux from. In an ideal world with steady seeing, this would
have a single value. However, seeing is very rarely steady, and can
exhibit very variable behaviour in a night, or even within
minutes. Thus a commonly used option is the ‘variable’ aperture option
(set in the reduce file). This scales the radius of the extraction
aperture to a multiple of the FWHM of the stellar profiles of the
given frame. A single mean value of FWHM is established through
profile fits to the targets and thus the same extraction radius is
used for all targets. Useful values for the scale factor range from
1.5 to 2.5. Stellar profiles have extended wings, so one cane never
include all the target flux in the aperture. Instead the hope is that
the <em>same</em> fraction of flux is missed from both target and comparison,
which then cancels when performing relative photometry. The exact
choice of scale is not easy, as it represents a balance between
increasing statistical noise for large radii versus increasing
systematic noise for small radii when the fraction of flux lost from
the apertures becomes large. Bright targets tend to push the choice
towards large radii, while faint targets are better with small
radii. The key is to try different values and compare the results side
by side.</p>
<p>Sometimes one might have no suitable comparison star, or only ones of very
different colour to the target such that they are bright in some bands but
faint in others. If the weather is photometric, then extraction of just the
target with a large aperture, reminiscent of the old days of photometry with
photomultipliers through 10 or 15 arcsec diameter apertures, may be in order.
It is also possible to use the comparison star on one band to correct for
short timescale fluctuations in another where the comparison may be faint, but
one should then typically use a larger than normal radius because the profiles
of different bands are unlikely to be the same, and one also then needs to
allow for differential atmospheric extinction over longer timescales.</p>
<p>A final rare possibility is to use a target as its own comparison. This can be
useful if an object has very different behaviour at different wavelengths but
no suitable comparison. A good example of this is the star V471 Tau
which shows an eclipse of a white dwarf that is deep at short wavelengths but
shallow at long wavelengths.</p>
</section>
<section id="profile-fitting">
<h2><a class="toc-backref" href="#id8" role="doc-backlink">Profile fitting</a><a class="headerlink" href="#profile-fitting" title="Link to this heading">¶</a></h2>
<p>In order to measure the FWHM to set the aperture size, HiPERCAM uses one of two
possible forms of stellar profile, namely a 2D gaussian or “Moffat” profile,
in each case symmetric. The gaussian profile is described by the following
relation</p>
<div class="math">
<p><span class="math">f(r) = h \exp \left(- \alpha r^2\right),</span></p>
</div><p>where <span class="math">r</span> is the distance from the centre of the gaussian, <span class="math">h</span> is
its height, and <span class="math">\alpha</span> is defined by the FWHM of the profile according
to</p>
<div class="math">
<p><span class="math">\alpha = \frac{4 \ln 2}{(\text{FWHM})^2}.</span></p>
</div><p>Moffat profiles (<a class="reference external" href="http://adsabs.harvard.edu/abs/1969A%26A.....3..455M">Moffat 1969</a>) usually provide much
better fits to stellar profiles than gaussians. Moffat profiles are described
by</p>
<div class="math">
<p><span class="math">f(r) = \frac{h}{(1 + \alpha r^2)^\beta},</span></p>
</div><p>where now <span class="math">\alpha</span> is a function of both the FWHM and <span class="math">\beta</span>:</p>
<div class="math">
<p><span class="math">\alpha = \frac{4(2^{1/\beta} - 1)}{(\text{FWHM})^2}.</span></p>
</div><p>Moffat profiles tend to gaussians as <span class="math">\beta \rightarrow \infty</span>, anything
a gaussian can fit, they can. Their advantage is their more extended
wings which often give a better fit to real stellar profiles. However, they
also have a downside in that some profiles seem to fall off more steeply than
gaussians and when fitted with Moffat profiles, there is a tendency for the
value of <span class="math">\beta</span> to climb to very large values. This probably depends
upon the telescope and instrument, so should be the subject of
experimentation. In order to be integrable, they should have <span class="math">\beta &gt; 1</span>.
The profile fitting is implemented in <code class="xref py py-mod docutils literal notranslate"><span class="pre">hipercam.fitting</span></code> on top of the
Levenberg-Marquardt fitting routine <code class="xref py py-func docutils literal notranslate"><span class="pre">scipy.optimize.leastsq()</span></code>. It is
designed to be able to sub-pixellate, i.e. the profile is evaluated at
multiple points within pixels to allow for cases where the seeing becomes
small compared to the pixels. This is controlled by the parameter <cite>fit_ndiv</cite>
in the reduce file. It’s use does come with a speed penalty owing to the
larger number of function evaluations.</p>
</section>
<section id="optimal-photometry">
<h2><a class="toc-backref" href="#id9" role="doc-backlink">Optimal photometry</a><a class="headerlink" href="#optimal-photometry" title="Link to this heading">¶</a></h2>
<p>For faint targets a significant improvement can be made by adding in the flux
in a weighted manner, as discussed by <a class="reference external" href="http://adsabs.harvard.edu/abs/1998MNRAS.296..339N">Naylor (1998)</a>. As Naylor discusses,
rather than the precisely “optimal weights” which are proportional to the
expected fraction of target flux in a pixel divided by its variance, it is
better in practice to use weights simply proportional to the expected fraction
alone, as determined with some sort of profile fit. This is because this
approach is robust to poor profile fits, which are not uncommon
given the vagaries of seeing and guiding. This contrasts with the optimal
extraction used in spectroscopy where the multiple pixels in the dispersion
direction allow the development of good models of the spatial profile.</p>
<p>An example of the improvement possible with optimal photometry in shown in
<a class="reference internal" href="#fig-optimal"><span class="std std-numref">Fig. 4</span></a>.</p>
<figure class="align-center" id="id3">
<span id="fig-optimal"></span><a class="reference internal image-reference" href="_images/optimal.png"><img alt="optimal versus normal photometry" src="_images/optimal.png" style="width: 800.0px; height: 500.0px;" />
</a>
<figcaption>
<p><span class="caption-number">Fig. 4 </span><span class="caption-text">Normal (blue) versus optimal (green) photometry of the same target relative
to a much brighter comparison. The optimal photometry has been moved up by
0.01 for clarity.</span><a class="headerlink" href="#id3" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p>In this case a faint target was chosen, and there is indeed an obvious
improvement in signal-to-noise. The aperture radius in this case was set to
1.8 times the FWHM of the profiles, and, while a smaller size might yield a
higher signal-to-noise for the normal photometry, one would not want to cut
down very much because of loss of flux.</p>
<p>The choice of weights is designed so that one does not need the profile to be
perfectly modelled, but it does require that both target and comparison have
the <em>same</em> profile. If this is not the case, e.g. the CCDs have significant
tilt leading to a FWHM that varies with position, then optimal photometry can
suffer from systematic errors that make things worse. As usual, such problems
manifest themselves most on bright targets, so one should not simply choose
‘optimal’ over ‘normal’ by default. (I use ‘normal’ most of the time.)</p>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper"><h3>Table of Contents</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="news.html">HiPERCAM pipeline news</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="observers.html">Observer’s guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="telescope.html">At the telescope</a></li>
<li class="toctree-l2"><a class="reference internal" href="reduction.html">Reduction</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="organisation.html">File organisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="checklists.html">Observing checklists</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="commands.html">HiPERCAM commands</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/api.html">The API</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Getting the software</a></li>
<li class="toctree-l1"><a class="reference internal" href="files.html">Useful files</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/bugs.html">Reporting problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="makingmovies.html">Making HiPERCAM movies</a></li>
<li class="toctree-l1"><a class="reference internal" href="phaseII.html">HiPERCAM Phase II</a></li>
</ul>


  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="reduction.html"
                          title="previous chapter">Reduction</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="organisation.html"
                          title="next chapter">File organisation</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/photometry.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<form action="search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
<footer class="footer">
  <p class="pull-right">
    <a href="_sources/photometry.rst.txt"
       rel="nofollow">Page Source</a> &nbsp;
    <a href="#">Back to Top</a></p>
  <p>
    &copy; Copyright 2017, T.R. Marsh.<br/>
    Created using <a href="http://www.sphinx-doc.org/en/stable/">Sphinx</a> 7.4.7. &nbsp;
  </p>
</footer>
  </body>
</html>